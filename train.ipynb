{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Histopathologic Cancer Detection\n",
    "*Training of a model for identification of metastatic tissue in  histopathologic scans of lymph node sections.*  \n",
    "*https://www.kaggle.com/c/histopathologic-cancer-detection*\n",
    "\n",
    "***\n",
    "\n",
    "## Dataset details:\n",
    "\n",
    "The images are 96x96 pixels with 3 channels (RGB). They are labelled as metastatic only if there is cancerous cells inside the center 32x32 pixel region of the image. Presence of tumor cells outside of this region does not influence the label.\n",
    "\n",
    "I believe this caveat in the method of labelling the images doesn't matter, because if there's no cancer cells inside the center of the image, why would there be cancer cells outside? However, I don't have enough medical knowledge to know if this assumption is correct, so multiple training sessions will be used to determine what is the best approach to the problem.\n",
    "\n",
    "The file `data/train_labels.csv` contains a dataframe with image ids and theirs respective labels.\n",
    "The data for training and validation is in `data/train`. The trained model will be used to predict the labels of the images in the `data/test` folder.\n",
    "\n",
    "## Preparing the Images:\n",
    "\n",
    "Before anything else, the training images were separated into 2 folders: *metastatic* and *non-metastatic*. This is an important step, because it enables the use of `flow_from_directory` method from `keras.preprocessing.image.ImageDataGenerator`.\n",
    "\n",
    "## Models:\n",
    "\n",
    "1. **Full-Image-Gray**: a model trained on the full 96x96 image in gray-scale.\n",
    "2. **Full-Image-RGB**: a model trained on the full 96x96 image in RGB.\n",
    "3. **Center-Image-Gray**: a model trained on the 32x32 center patch in gray-scale.\n",
    "4. **Center-Image-RGB**: a model trained on the 32x32 center patch in RGB.\n",
    "\n",
    "All models will make use of data augmentation techniques.\n",
    "Also, the center-image models should use zoom-outs instead of zoom-ins for data augmentation.\n",
    "\n",
    "## Model Architecture:\n",
    "\n",
    "### Observations:\n",
    "1. Does using whitening and increasing brightness on the data augmentation help the model?\n",
    "2. Maybe add some more metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:20:03.032788Z",
     "start_time": "2019-04-07T23:20:01.987808Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import augment_2d\n",
    "from tensorflow.python.keras.layers import (Dense, Conv2D, MaxPool2D, Dropout,\n",
    "                                            Flatten, BatchNormalization, \n",
    "                                            Activation, Lambda, MaxPooling2D,\n",
    "                                            GlobalAveragePooling2D, Input)\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.callbacks import (ReduceLROnPlateau,\n",
    "                                               EarlyStopping, ModelCheckpoint,\n",
    "                                              CSVLogger)\n",
    "from tensorflow.python.keras.utils import multi_gpu_model\n",
    "from tensorflow.python.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.python.keras.applications import MobileNet\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.backend import set_session\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "# set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Defining constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:20:03.038223Z",
     "start_time": "2019-04-07T23:20:03.034751Z"
    },
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "images_shape = (96, 96, 3)\n",
    "target_size = (128, 128)\n",
    "\n",
    "datagen_conf = {\n",
    "    'target_size': target_size,\n",
    "    'color_mode': 'rgb',\n",
    "    'batch_size': batch_size,\n",
    "    'class_mode': 'sparse'\n",
    "}\n",
    "\n",
    "data_augmentation_conf = {\n",
    "    'rotation': 180,\n",
    "    'horizontal_flip': True,\n",
    "    'vertical_flip': True,\n",
    "    'crop': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapating MobileNet for this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:20:08.489156Z",
     "start_time": "2019-04-07T23:20:03.040007Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "base_model = MobileNet(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(128, 128, 3)\n",
    ")\n",
    "\n",
    "# Freezing base model pre-trained layers\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "inputs = Input(shape=images_shape, name='input')\n",
    "\n",
    "x = Lambda(augment_2d,\n",
    "                arguments={\n",
    "                    'rotation': 180,\n",
    "                    'horizontal_flip': True,\n",
    "                    'vertical_flip': True,\n",
    "                    'crop': True,\n",
    "                }, name='augmentation_layer')(inputs)\n",
    "\n",
    "x = base_model(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "y = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:20:08.498603Z",
     "start_time": "2019-04-07T23:20:08.490241Z"
    },
    "pycharm": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "augmentation_layer (Lambda)  (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "mobilenet_1.00_128 (Model)   multiple                  3228864   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,754,690\n",
      "Trainable params: 525,826\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Defining the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:20:08.938956Z",
     "start_time": "2019-04-07T23:20:08.499927Z"
    },
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# optimizer = Adam()\n",
    "optimizer = RMSprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Defining callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:20:08.991067Z",
     "start_time": "2019-04-07T23:20:08.940697Z"
    },
    "code_folding": [],
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "# Model checkpoint callback configuration:\n",
    "model_name = \"cancer-model.h5\"\n",
    "checkpoint = ModelCheckpoint(model_name, save_best_only=True)\n",
    "\n",
    "# Logging the epochs results:\n",
    "csv_logger = CSVLogger('epochs.log')\n",
    "\n",
    "# Stopping training early if val_loss has stopped falling for 15 epochs\n",
    "early_stop = EarlyStopping(patience=15)\n",
    "\n",
    "callbacks = [learning_rate_reduction, checkpoint, csv_logger, early_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Compilling model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:20:09.315146Z",
     "start_time": "2019-04-07T23:20:08.992437Z"
    },
    "code_folding": [],
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with only 1 GPU.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "except:\n",
    "    print(\"Continuing with only 1 GPU.\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Creating generator for the data flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:20:15.235193Z",
     "start_time": "2019-04-07T23:20:09.317240Z"
    },
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 198022 images belonging to 2 classes.\n",
      "Found 22003 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train', **datagen_conf)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation', **datagen_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Calculating weights for the unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:20:15.267169Z",
     "start_time": "2019-04-07T23:20:15.237080Z"
    },
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/41815354/keras-flow-from-directory-over-or-undersample-a-class\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Fitting the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:20:15.389194Z",
     "start_time": "2019-04-07T23:20:15.268421Z"
    },
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# model.fit_generator(\n",
    "#         train_generator,\n",
    "#         epochs=epochs,\n",
    "#         validation_data=validation_generator,\n",
    "#         class_weight=class_weights,\n",
    "#         callbacks=callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
