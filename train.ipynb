{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Histopathologic Cancer Detection\n",
    "*Training of a model for identification of metastatic tissue in  histopathologic scans of lymph node sections.*  \n",
    "*https://www.kaggle.com/c/histopathologic-cancer-detection*\n",
    "\n",
    "***\n",
    "\n",
    "## Dataset details:\n",
    "\n",
    "The images are 96x96 pixels with 3 channels (RGB). They are labelled as metastatic only if there is cancerous cells inside the center 32x32 pixel region of the image. Presence of tumor cells outside of this region does not influence the label.\n",
    "\n",
    "This caveat in the method of labelling the images doesn't seems to matter, because if there's no cancer cells inside the center of the image, why would there be cancer cells outside? However, this assumption could be wrong, so multiple training sessions will be used to determine what is the best approach to the problem.\n",
    "\n",
    "The file `data/train_labels.csv` contains a dataframe with image ids and theirs respective labels.\n",
    "The data for training and validation is in `data/train`. The trained model will be used to predict the labels of the images in the `data/test` folder.\n",
    "\n",
    "## Preparing the Images:\n",
    "\n",
    "Before anything else, the training images were separated into 2 folders: *metastatic* and *non-metastatic*. This is an important step, because it enables the use of `flow_from_directory` method from `keras.preprocessing.image.ImageDataGenerator`.\n",
    "\n",
    "## First Set of Models:\n",
    "\n",
    "1. **Full-Image-Gray**: a model trained on the full 96x96 image in gray-scale.\n",
    "2. **Full-Image-RGB**: a model trained on the full 96x96 image in RGB.\n",
    "3. **Center-Image-Gray**: a model trained on the 32x32 center patch in gray-scale.\n",
    "4. **Center-Image-RGB**: a model trained on the 32x32 center patch in RGB.\n",
    "\n",
    "### Results:\n",
    "\n",
    "It rapidly became apparent that using only the center patch of the image was not beneficial to the model, it ended reducing validation accuracy in every test. Also, models trained on grasycale images performed equaly and even better than those trained on RGB images.\n",
    "\n",
    "The most successful model in this set used the full image in grayscale: it was a simple 9216-32c5-p2-64c5-p2-512-10, which is a popular architeture for the MNIST digit dataset. With some small changes (some dropouts were added), this model achieved ~86.6% validation accuracy at the cancer classification task.\n",
    "\n",
    "Some other models were tested, with more dense/convolutional layers and with varying parameters, but all performed worse.\n",
    "\n",
    "\n",
    "## Second Set of Models:\n",
    "\n",
    "Intending to pass the 90% validation accuracy mark, transfer learning was used at this set of models.\n",
    "\n",
    "The best models were trained \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Model Architecture:\n",
    "\n",
    "### Observations:\n",
    "1. Does using whitening and increasing brightness on the data augmentation help the model?\n",
    "2. Maybe add some more metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:47:02.661930Z",
     "start_time": "2019-04-07T23:47:01.599821Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import auc_roc\n",
    "from tensorflow.python.keras.layers import (Dense, Conv2D, MaxPool2D, Dropout,\n",
    "                                            Flatten, BatchNormalization, \n",
    "                                            Activation, Lambda, MaxPooling2D,\n",
    "                                            GlobalAveragePooling2D, Input)\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.callbacks import (ReduceLROnPlateau,\n",
    "                                               EarlyStopping, ModelCheckpoint,\n",
    "                                              CSVLogger)\n",
    "from tensorflow.python.keras.utils import multi_gpu_model\n",
    "from tensorflow.python.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.python.keras.applications import MobileNet, densenet\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.backend import set_session\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "# set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Defining constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:47:02.669031Z",
     "start_time": "2019-04-07T23:47:02.663931Z"
    },
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "images_shape = (96, 96, 3)\n",
    "target_size = (224, 224, 3)\n",
    "\n",
    "datagen_conf = {\n",
    "    'target_size': target_size[:2],\n",
    "    'color_mode': 'rgb',\n",
    "    'batch_size': batch_size,\n",
    "    'class_mode': 'sparse'\n",
    "}\n",
    "\n",
    "# TODO: normalize the data using mean and std of the dataset\n",
    "# reference: https://www.kaggle.com/qitvision/a-complete-ml-pipeline-fast-ai\n",
    "# TODO: find optimal hyperparameters for LR and weigth decay\n",
    "# TODO: visualization is a good way of understanding what are the images the model struggles with. It might also reveal something about the dataset such as bad quality data.\n",
    "# TODO: heatmap visualization\n",
    "\n",
    "# TODO: try new data augmentation techniques, and check what each of the\n",
    "#  transformations does to the image.\n",
    "augmentation_conf = {\n",
    "    'rotation_range': 180,\n",
    "    'horizontal_flip': True,\n",
    "    'vertical_flip': True,\n",
    "    'zoom_range': 0.2,\n",
    "    'width_shift_range': 0.1,\n",
    "    'height_shift_range': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapating MobileNet for this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:47:07.571435Z",
     "start_time": "2019-04-07T23:47:02.673423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dedeco/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Imports the pre-trained model without the last (prediction) layer.\n",
    "base_model = densenet.DenseNet121(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=target_size\n",
    ")\n",
    "\n",
    "# Creating the new classification layers of the model\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "y = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.inputs, outputs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:47:07.584378Z",
     "start_time": "2019-04-07T23:47:07.574989Z"
    },
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable parameters: \t\t6955906\n",
      "Non-trainable paramenters: \t83648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainable_params = int(np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n",
    "non_trainable_params = int(np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n",
    "\n",
    "print(f\"\\nTrainable parameters: \\t\\t{trainable_params}\")\n",
    "print(f\"Non-trainable paramenters: \\t{non_trainable_params}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Defining the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:47:15.104802Z",
     "start_time": "2019-04-07T23:47:15.039219Z"
    },
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# optimizer = Adam()\n",
    "optimizer = RMSprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Defining callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:47:15.287773Z",
     "start_time": "2019-04-07T23:47:15.281581Z"
    },
    "code_folding": [],
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "# Model checkpoint callback configuration:\n",
    "model_name = \"cancer-model.h5\"\n",
    "checkpoint = ModelCheckpoint(model_name, save_best_only=True)\n",
    "\n",
    "# Logging the epochs results:\n",
    "csv_logger = CSVLogger('epochs.log')\n",
    "\n",
    "# Stopping training early if val_loss has stopped falling for 15 epochs\n",
    "early_stop = EarlyStopping(patience=15)\n",
    "\n",
    "callbacks = [learning_rate_reduction, checkpoint, csv_logger, early_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Compilling model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:47:15.849535Z",
     "start_time": "2019-04-07T23:47:15.550791Z"
    },
    "code_folding": [],
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with only 1 GPU.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/dedeco/projects/cancer/utils/metrics.py:6: streaming_auc (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.metrics.auc. Note that the order of the labels and predictions arguments has been switched.\n",
      "WARNING:tensorflow:From /home/dedeco/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/dedeco/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "except:\n",
    "    print(\"Continuing with only 1 GPU.\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\", auc_roc]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Creating generator for the data flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:47:21.494262Z",
     "start_time": "2019-04-07T23:47:15.851638Z"
    },
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, **augmentation_conf)\n",
    "\n",
    "# TODO: is adding augmentation to the validation generator TTA?\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, **augmentation_conf)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train', **datagen_conf)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation', **datagen_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Calculating weights for the unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:47:21.536413Z",
     "start_time": "2019-04-07T23:47:21.497678Z"
    },
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/41815354/keras-flow-from-directory-over-or-undersample-a-class\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Fitting the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T23:47:45.902754Z",
     "start_time": "2019-04-07T23:47:21.537919Z"
    },
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
